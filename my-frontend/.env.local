# Frontend local runtime variables
# Backend URL - Railway production (commented out for local development)
# NEXT_PUBLIC_API_URL=https://bisman-erp-backend-production.up.railway.app

# For local development, use local backend:
NEXT_PUBLIC_API_URL=http://localhost:3001

# Use Next.js API proxy instead of direct backend calls (eliminates CORS)
# Set to 'true' only if you want to bypass Next.js proxy
NEXT_PUBLIC_DIRECT_BACKEND=false

# Debug authentication flow (set to '1' to enable detailed logging)
DEBUG_AUTH=1

# Database connection for Prisma
DATABASE_URL="postgresql://postgres@localhost:5432/BISMAN"

## Ollama - Local development
# Optional alias
OLLAMA_HOST=http://localhost:11434

## (Old) ngrok example – leave commented unless tunneling directly to Ollama
# OLLAMA_HOST=https://your-ngrok-subdomain.ngrok-free.dev

# Public env vars for browser-side access (keep URL unset to force proxy)
NEXT_PUBLIC_OLLAMA_MODEL=tinyllama:latest
OLLAMA_MODEL=tinyllama:latest

# Force server relay and use generate-only for older Ollama
OLLAMA_FORCE_PROXY=true
OLLAMA_PREFER_GENERATE=true

## Production (Railway) — set these on the service, not here
# OLLAMA_FORCE_PROXY=true
# OLLAMA_PREFER_GENERATE=true
# OLLAMA_MODEL=tinyllama:latest
# NEXT_PUBLIC_OLLAMA_MODEL=tinyllama:latest


# Central AI (Railway Open WebUI or proxy)
AI_BASE_URL=https://open-webui-production-6e46.up.railway.app
AI_DEFAULT_MODEL=llama3
AI_KEY=

# Tawk inline chat
NEXT_PUBLIC_TAWK_ENABLED=true
# Set these from your Tawk property
NEXT_PUBLIC_TAWK_PROPERTY_ID=
NEXT_PUBLIC_TAWK_WIDGET_ID=REPLACE_WITH_WIDGET_ID

BACKEND_URL=http://localhost:5000
