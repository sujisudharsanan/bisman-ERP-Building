# AI service (Railway Ollama)
# Base URL of your Railway app that forwards native Ollama endpoints
AI_BASE_URL=https://YOUR_RAILWAY_APP.up.railway.app
AI_KEY=
AI_DEFAULT_MODEL=llama3
# Remote Ollama (Windows via ngrok)
OLLAMA_URL=https://YOUR-NGROK-SUBDOMAIN.ngrok-free.dev
OLLAMA_MODEL=llama3:latest
# Frontend Environment Variables
# Copy this file to .env.local and fill in your actual values

# Backend API URL
NEXT_PUBLIC_API_URL=http://localhost:3000

# Environment
NODE_ENV=development

# Optional: Analytics, monitoring, etc.
NEXT_PUBLIC_ANALYTICS_ID=
