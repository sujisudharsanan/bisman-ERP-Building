# âœ… AI Module - Installation & Verification Checklist

## ðŸ“¦ Files Created - Verification

### Backend Files (my-backend/)

#### Services
- [ ] `services/aiService.js` - Core AI integration with Ollama
- [ ] `services/aiAnalyticsEngine.js` - Analytics and reporting engine

#### Routes
- [ ] `routes/aiRoute.js` - AI query endpoints (6 endpoints)
- [ ] `routes/aiAnalyticsRoute.js` - Analytics endpoints (8 endpoints)

#### Automation
- [ ] `cron/aiAnalyticsJob.js` - Scheduled tasks and automation

#### Database
- [ ] `migrations/ai-module-setup.sql` - Complete database schema

#### Configuration Updates
- [ ] `app.js` - Routes registered âœ…
- [ ] `server.js` - Cron initialized âœ…
- [ ] `package.json` - Dependencies added âœ…

### Frontend Files (my-frontend/)

#### Pages
- [ ] `src/modules/common/pages/ai-assistant.tsx` - Complete chat UI

### Documentation Files

- [ ] `AI_MODULE_COMPLETE_GUIDE.md` - 500+ line comprehensive guide
- [ ] `AI_MODULE_QUICK_START.md` - 5-minute setup guide
- [ ] `AI_MODULE_IMPLEMENTATION_SUMMARY.md` - Complete implementation summary
- [ ] `AI_MODULE_ARCHITECTURE.md` - Visual architecture diagram
- [ ] `install-ai-module.sh` - Automated installation script (executable)

---

## ðŸš€ Installation Steps

### Step 1: Prerequisites Check

```bash
# Check Node.js (18+ required)
node --version

# Check npm
npm --version

# Check PostgreSQL
psql --version

# Verify you're in ERP root directory
ls -la my-backend my-frontend
```

**Expected:**
- âœ… Node.js v18.0.0 or higher
- âœ… npm v8.0.0 or higher
- âœ… PostgreSQL 12+ available
- âœ… Both my-backend and my-frontend directories exist

---

### Step 2: Install Ollama

#### Automated (Recommended)
```bash
./install-ai-module.sh
```

#### Manual
```bash
# macOS/Linux
curl -fsSL https://ollama.com/install.sh | sh

# Windows
# Download from: https://ollama.com/download
```

**Verification:**
```bash
ollama --version
```

**Expected:**
- âœ… Ollama version displayed

---

### Step 3: Download AI Model

```bash
# Download Mistral (recommended)
ollama pull mistral

# Verify download
ollama list
```

**Expected:**
- âœ… `mistral:latest` appears in model list
- âœ… Size: ~4.1 GB

**Alternative models:**
```bash
# Llama 3 (more capable, slower)
ollama pull llama3

# Phi-3 (lightweight, faster)
ollama pull phi3
```

---

### Step 4: Start Ollama Service

```bash
# Start Ollama (keep this terminal open)
ollama serve
```

**Verification:**
```bash
# In new terminal
curl http://localhost:11434/api/tags
```

**Expected:**
- âœ… JSON response with available models
- âœ… No connection errors

---

### Step 5: Install Backend Dependencies

```bash
cd my-backend

# Install required packages
npm install langchain@^0.3.0 node-cron@^3.0.3

# Verify installation
npm list langchain node-cron
```

**Expected:**
- âœ… `langchain@0.3.x` installed
- âœ… `node-cron@3.0.x` installed
- âœ… No peer dependency warnings

---

### Step 6: Configure Environment Variables

```bash
# Edit .env file
nano my-backend/.env

# Add these lines at the end:
```

```env
# ============================================
# AI Module Configuration
# ============================================
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=mistral
AI_CRON_ENABLED=true
AI_DAILY_REPORT_TIME=0 20 * * *
AI_CACHE_CLEANUP_TIME=0 2 * * *
AI_DATA_RETENTION_DAYS=90
```

**Verification:**
```bash
grep "OLLAMA" my-backend/.env
```

**Expected:**
- âœ… All AI environment variables present

---

### Step 7: Run Database Migration

```bash
# Using psql directly
psql -h YOUR_HOST -U YOUR_USER -d YOUR_DATABASE -f my-backend/migrations/ai-module-setup.sql

# OR using connection string
psql "postgresql://user:pass@host:5432/dbname" -f my-backend/migrations/ai-module-setup.sql
```

**Verification:**
```bash
# Check tables created
psql -h YOUR_HOST -U YOUR_USER -d YOUR_DATABASE -c "\dt ai_*"
```

**Expected:**
- âœ… `ai_conversations` table exists
- âœ… `ai_reports` table exists
- âœ… `ai_settings` table exists
- âœ… `ai_analytics_cache` table exists

**Verify functions:**
```bash
psql -h YOUR_HOST -U YOUR_USER -d YOUR_DATABASE -c "\df cleanup_*"
```

**Expected:**
- âœ… `cleanup_old_ai_conversations` function exists
- âœ… `cleanup_ai_cache` function exists

---

### Step 8: Start Backend Server

```bash
cd my-backend

# Development mode
npm run dev

# Production mode
npm start
```

**Expected logs:**
```
[startup] API routes mounted
[app.js] âœ… AI Module routes loaded
[startup] âœ… AI Analytics cron jobs initialized
[startup] âœ… Server listening on http://0.0.0.0:8080
```

**Verification:**
```bash
# Test health endpoint
curl http://localhost:3000/api/ai/health
```

**Expected response:**
```json
{
  "success": true,
  "status": "healthy",
  "model": "mistral",
  "baseUrl": "http://localhost:11434",
  "responsive": true,
  "message": "AI service is operational"
}
```

---

### Step 9: Start Frontend

```bash
cd my-frontend

# Development mode
npm run dev

# Production mode
npm run build && npm start
```

**Expected:**
- âœ… Frontend starts on http://localhost:3000
- âœ… No build errors
- âœ… No TypeScript errors

---

### Step 10: Test AI Assistant UI

1. **Open browser:** http://localhost:3000
2. **Login** to your ERP
3. **Navigate to:** `/ai-assistant` or find "AI Assistant" in sidebar
4. **Check status:** Should show ðŸŸ¢ "Online"

**Test chat:**
- Type: "Hello, can you help me?"
- Press Enter or click Send
- âœ… AI responds within 5-10 seconds
- âœ… Message appears in chat history

**Test reports:**
- Click "Reports" tab
- Click "Generate New Report"
- Wait 20-30 seconds
- âœ… Report appears in list

---

## ðŸ§ª Comprehensive Testing

### Test 1: AI Health Check

```bash
curl http://localhost:3000/api/ai/health
```

**Success criteria:**
- âœ… Returns HTTP 200
- âœ… `"status": "healthy"`
- âœ… Response time < 1 second

---

### Test 2: AI Query (with authentication)

```bash
# Get your JWT token from browser dev tools or login response
TOKEN="YOUR_JWT_TOKEN_HERE"

curl -X POST http://localhost:3000/api/ai/query \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"prompt": "Explain ERP systems in one sentence"}'
```

**Success criteria:**
- âœ… Returns HTTP 200
- âœ… Response contains AI-generated text
- âœ… Response saved to database

---

### Test 3: Verify Database Storage

```bash
psql -h YOUR_HOST -U YOUR_USER -d YOUR_DATABASE -c "SELECT COUNT(*) FROM ai_conversations;"
```

**Success criteria:**
- âœ… Count increases after each query
- âœ… Conversations include user_id and tenant_id

---

### Test 4: Analytics Report Generation

```bash
curl http://localhost:3000/api/ai/analytics/generate-report \
  -H "Authorization: Bearer $TOKEN"
```

**Success criteria:**
- âœ… Returns HTTP 200
- âœ… Report contains `sales_report` and `inventory_report`
- âœ… Executive summary present
- âœ… Report saved to database and file system

---

### Test 5: Verify File Storage

```bash
ls -lh my-backend/reports/ai/
```

**Success criteria:**
- âœ… Directory exists
- âœ… JSON files present (if reports generated)
- âœ… Files named: `erp_ai_insight_YYYY-MM-DD_*.json`

---

### Test 6: Cron Jobs Verification

```bash
# Check backend logs for cron initialization
grep "AI Cron" my-backend/backend.log
```

**Expected:**
```
[AI Cron] Initializing scheduled tasks...
[AI Cron] âœ… Scheduled daily reports at: 0 20 * * *
[AI Cron] âœ… Scheduled cleanup tasks at: 0 2 * * *
[AI Cron] ðŸš€ All cron jobs initialized successfully
```

---

### Test 7: Multi-Tenant Isolation

**As Super Admin (Tenant 1):**
```bash
# Query should only return tenant 1 data
curl http://localhost:3000/api/ai/conversations \
  -H "Authorization: Bearer $SUPER_ADMIN_TOKEN"
```

**As Enterprise Admin:**
```bash
# Query should return all tenant data
curl http://localhost:3000/api/ai/conversations \
  -H "Authorization: Bearer $ENTERPRISE_ADMIN_TOKEN"
```

**Success criteria:**
- âœ… Super admin sees only their tenant data
- âœ… Enterprise admin sees all data
- âœ… No cross-tenant data leakage

---

### Test 8: Error Handling

#### Test with Ollama stopped:
```bash
# Stop Ollama
pkill ollama

# Try query
curl http://localhost:3000/api/ai/health
```

**Expected:**
- âœ… Returns `"status": "unhealthy"`
- âœ… Helpful error message
- âœ… UI shows "Offline" status

#### Restart Ollama:
```bash
ollama serve &

# Wait 3 seconds
sleep 3

# Test again
curl http://localhost:3000/api/ai/health
```

**Expected:**
- âœ… Returns `"status": "healthy"`
- âœ… UI shows "Online" status

---

## ðŸ” Security Verification

### Test 1: Authentication Required

```bash
# Try without token
curl -X POST http://localhost:3000/api/ai/query \
  -H "Content-Type: application/json" \
  -d '{"prompt": "test"}'
```

**Expected:**
- âœ… Returns HTTP 401 Unauthorized
- âœ… Error: "Missing or malformed token"

---

### Test 2: Health Endpoint Public

```bash
# Health check without token should work
curl http://localhost:3000/api/ai/health
```

**Expected:**
- âœ… Returns HTTP 200
- âœ… No authentication required

---

### Test 3: Tenant Data Isolation

**Verify conversations table:**
```sql
SELECT user_id, tenant_id, message 
FROM ai_conversations 
ORDER BY created_at DESC 
LIMIT 5;
```

**Expected:**
- âœ… Each conversation has tenant_id
- âœ… No null tenant_id for non-admin users

---

## ðŸ“Š Performance Verification

### Test 1: Response Times

```bash
# Measure AI query response time
time curl -X POST http://localhost:3000/api/ai/query \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{"prompt": "What is 2+2?"}'
```

**Acceptable:**
- Simple query: 2-5 seconds
- Complex query: 10-30 seconds
- (Depends on hardware and model)

---

### Test 2: Resource Usage

```bash
# Check Ollama memory usage
ps aux | grep ollama

# Check backend memory
ps aux | grep node
```

**Acceptable:**
- Ollama: 2-8 GB RAM (depends on model)
- Backend: 100-500 MB RAM

---

### Test 3: Concurrent Requests

```bash
# Send 5 queries simultaneously
for i in {1..5}; do
  curl -X POST http://localhost:3000/api/ai/query \
    -H "Content-Type: application/json" \
    -H "Authorization: Bearer $TOKEN" \
    -d "{\"prompt\": \"Test query $i\"}" &
done
wait
```

**Expected:**
- âœ… All requests complete successfully
- âœ… No crashes or errors
- âœ… Responses may be sequential (queued)

---

## ðŸŽ¯ Success Criteria Summary

Your AI module is **FULLY OPERATIONAL** when:

### Backend
- âœ… Ollama service running
- âœ… AI model downloaded (mistral/llama3)
- âœ… Backend server started without errors
- âœ… `/api/ai/health` returns healthy
- âœ… All AI routes respond correctly
- âœ… Database tables created
- âœ… Cron jobs initialized

### Frontend
- âœ… Frontend builds without errors
- âœ… `/ai-assistant` page loads
- âœ… Status shows "Online" (green)
- âœ… Can send messages
- âœ… AI responds correctly
- âœ… Conversation history loads
- âœ… Reports tab functional

### Security
- âœ… Authentication enforced
- âœ… Tenant isolation works
- âœ… Role-based access correct
- âœ… No unauthorized access possible

### Performance
- âœ… Response times acceptable
- âœ… Memory usage reasonable
- âœ… Concurrent requests handled
- âœ… No memory leaks

### Automation
- âœ… Cron jobs scheduled
- âœ… Daily reports generate
- âœ… Cache cleanup runs
- âœ… Data retention enforced

---

## ðŸ› Troubleshooting Quick Reference

| Issue | Check | Fix |
|-------|-------|-----|
| Health check fails | `curl http://localhost:11434/api/tags` | `ollama serve` |
| Model not found | `ollama list` | `ollama pull mistral` |
| Auth errors | JWT token validity | Re-login and get fresh token |
| No cron jobs | `AI_CRON_ENABLED` in .env | Set to `true` |
| DB errors | Tables exist: `\dt ai_*` | Re-run migration |
| Slow responses | Model size | Switch to `phi3` |
| UI shows offline | Backend logs | Check Ollama and backend |

---

## ðŸ“ž Support Checklist

Before asking for help, verify:

1. âœ… Ollama is running: `curl http://localhost:11434/api/tags`
2. âœ… Model downloaded: `ollama list`
3. âœ… Backend started: `curl http://localhost:3000/api/ai/health`
4. âœ… Database migrated: `psql -c "\dt ai_*"`
5. âœ… Dependencies installed: `npm list langchain node-cron`
6. âœ… Environment configured: `grep OLLAMA .env`
7. âœ… Logs checked: `tail -f backend.log | grep AI`

---

## ðŸŽ‰ Deployment Checklist

### Pre-Production

- [ ] All tests pass locally
- [ ] Documentation reviewed
- [ ] Team trained on AI features
- [ ] Backup strategy in place

### Production Deployment

- [ ] Ollama installed on server
- [ ] Model downloaded on server
- [ ] Ollama set to auto-start
- [ ] Database migration applied
- [ ] Environment variables set
- [ ] Backend deployed with AI routes
- [ ] Frontend deployed with AI page
- [ ] Health monitoring configured
- [ ] Logs monitored
- [ ] Alerts set up

### Post-Production

- [ ] Test AI from production UI
- [ ] Verify cron jobs running
- [ ] Check first automated report
- [ ] Monitor resource usage
- [ ] Test all user roles
- [ ] Document production URLs
- [ ] Train support team

---

## ðŸ“š Documentation References

- **Quick Start:** `AI_MODULE_QUICK_START.md`
- **Complete Guide:** `AI_MODULE_COMPLETE_GUIDE.md`
- **Architecture:** `AI_MODULE_ARCHITECTURE.md`
- **Implementation Summary:** `AI_MODULE_IMPLEMENTATION_SUMMARY.md`

---

**Last Updated:** October 26, 2025  
**Status:** âœ… PRODUCTION READY  
**Version:** 1.0.0
