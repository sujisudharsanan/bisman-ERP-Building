#!/bin/bash

# Spark AI Diagnostic and Fix Script
# This script checks if Ollama is running and helps fix AI issues

echo "ðŸ” Diagnosing Spark AI Issues..."
echo "================================"
echo ""

# Check if Ollama is installed
echo "1ï¸âƒ£ Checking if Ollama is installed..."
if command -v ollama &> /dev/null; then
    echo "   âœ… Ollama is installed"
    OLLAMA_VERSION=$(ollama --version 2>&1 | head -1)
    echo "   ðŸ“¦ Version: $OLLAMA_VERSION"
else
    echo "   âŒ Ollama is NOT installed"
    echo ""
    echo "ðŸ“¥ To install Ollama:"
    echo "   curl -fsSL https://ollama.com/install.sh | sh"
    echo ""
    exit 1
fi

echo ""

# Check if Ollama service is running
echo "2ï¸âƒ£ Checking if Ollama service is running..."
if curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "   âœ… Ollama service is running on port 11434"
else
    echo "   âŒ Ollama service is NOT running"
    echo ""
    echo "ðŸš€ To start Ollama service:"
    echo "   ollama serve"
    echo ""
    echo "Or run in background:"
    echo "   nohup ollama serve > /dev/null 2>&1 &"
    echo ""
    exit 1
fi

echo ""

# Check available models
echo "3ï¸âƒ£ Checking available AI models..."
MODELS=$(curl -s http://localhost:11434/api/tags | python3 -c "import sys, json; data = json.load(sys.stdin); print('\n'.join([m['name'] for m in data.get('models', [])]))" 2>/dev/null)

if [ -z "$MODELS" ]; then
    echo "   âŒ No models installed"
    echo ""
    echo "ðŸ“¦ To install AI models:"
    echo "   ollama pull mistral        # Fast, good for general tasks (4GB)"
    echo "   ollama pull llama3         # More powerful (4.7GB)"
    echo "   ollama pull phi3           # Smaller, faster (2.3GB)"
    echo ""
    exit 1
else
    echo "   âœ… Found models:"
    echo "$MODELS" | while read model; do
        echo "      â€¢ $model"
    done
fi

echo ""

# Test AI query
echo "4ï¸âƒ£ Testing AI query..."
TEST_RESPONSE=$(curl -s -X POST http://localhost:11434/api/generate \
    -H "Content-Type: application/json" \
    -d '{
        "model": "mistral",
        "prompt": "Say hello in one word",
        "stream": false
    }' 2>&1)

if echo "$TEST_RESPONSE" | grep -q "response"; then
    echo "   âœ… AI query successful"
    RESPONSE=$(echo "$TEST_RESPONSE" | python3 -c "import sys, json; print(json.load(sys.stdin).get('response', ''))" 2>/dev/null)
    echo "   ðŸ¤– AI Response: $RESPONSE"
else
    echo "   âŒ AI query failed"
    echo "   Error: $TEST_RESPONSE"
    exit 1
fi

echo ""

# Check backend AI routes
echo "5ï¸âƒ£ Checking if backend is running..."
if curl -s http://localhost:4000/api/ai/health > /dev/null 2>&1; then
    echo "   âœ… Backend AI routes accessible"
    HEALTH=$(curl -s http://localhost:4000/api/ai/health)
    echo "   ðŸ“Š Health: $HEALTH"
else
    echo "   âš ï¸  Backend may not be running or AI routes not registered"
    echo ""
    echo "ðŸ”§ To start backend:"
    echo "   cd my-backend && npm start"
    echo ""
fi

echo ""

# Check if LangChain is installed
echo "6ï¸âƒ£ Checking LangChain dependencies..."
cd "$(dirname "$0")/my-backend"
if grep -q "@langchain/community" package.json 2>/dev/null; then
    echo "   âœ… LangChain is in package.json"
    
    if [ -d "node_modules/@langchain" ]; then
        echo "   âœ… LangChain is installed"
    else
        echo "   âš ï¸  LangChain not installed in node_modules"
        echo ""
        echo "ðŸ“¦ To install:"
        echo "   cd my-backend && npm install"
        echo ""
    fi
else
    echo "   âŒ LangChain not in dependencies"
    echo ""
    echo "ðŸ“¦ To install LangChain:"
    echo "   cd my-backend"
    echo "   npm install @langchain/community @langchain/core"
    echo ""
fi

echo ""
echo "================================"
echo "âœ… Spark AI Diagnostic Complete!"
echo ""
echo "ðŸ“ Summary:"
echo "   â€¢ Ollama: $(command -v ollama &> /dev/null && echo 'âœ… Installed' || echo 'âŒ Not installed')"
echo "   â€¢ Service: $(curl -s http://localhost:11434/api/tags > /dev/null 2>&1 && echo 'âœ… Running' || echo 'âŒ Not running')"
echo "   â€¢ Models: $([ -n "$MODELS" ] && echo "âœ… $(echo "$MODELS" | wc -l | tr -d ' ') installed" || echo 'âŒ None')"
echo "   â€¢ Backend: $(curl -s http://localhost:4000/api/ai/health > /dev/null 2>&1 && echo 'âœ… Running' || echo 'âš ï¸  Check status')"
echo ""

# Provide next steps
if ! command -v ollama &> /dev/null; then
    echo "ðŸ”§ Next Steps:"
    echo "   1. Install Ollama: curl -fsSL https://ollama.com/install.sh | sh"
elif ! curl -s http://localhost:11434/api/tags > /dev/null 2>&1; then
    echo "ðŸ”§ Next Steps:"
    echo "   1. Start Ollama: ollama serve &"
elif [ -z "$MODELS" ]; then
    echo "ðŸ”§ Next Steps:"
    echo "   1. Install a model: ollama pull mistral"
else
    echo "ðŸŽ‰ Everything looks good! Spark AI should be working."
    echo ""
    echo "ðŸ§ª Test it:"
    echo "   1. Go to: http://localhost:3000/common/ai-assistant"
    echo "   2. Or click the chat bot icon and talk to BISMAN AI"
fi

echo ""
